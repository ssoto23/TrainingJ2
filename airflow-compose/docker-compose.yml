---
version: '3.7'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    hostname: zookeeper
    container_name: zookeeper          
    ports:
      - "12181:12181"
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes"
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 12181
      ZOOKEEPER_TICK_TIME: 10000 
      ZOO_SERVERS: server.1=zookeeper:2888:3888

  broker:
    image: confluentinc/cp-kafka:latest
    hostname: broker
    restart: unless-stopped
    container_name: broker
    depends_on:
      - zookeeper    
    ports:
      - "19092:19092" 
      - "9080:9080"       
    volumes:
      - ./mount/jmx_exporter:/opt/jmx-exporter/      
    environment:      
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT    
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3    
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:12181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:19092
      JMX_PORT: "9999"
#      KAFKA_JMX_OPTS: "-javaagent:/opt/jmx-exporter/jmx_prometheus_javaagent-0.12.0.jar=9080:/opt/jmx-exporter/kafka.yml -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"

  broker2:
    image: confluentinc/cp-kafka:latest
    hostname: broker2
    restart: unless-stopped
    container_name: broker2
    depends_on:
      - zookeeper    
      - broker
    ports:
      - "19093:19093" 
      - "9081:9081"   
    volumes:
      - ./mount/jmx_exporter:/opt/jmx-exporter/      
    environment:      
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT    
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3    
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:12181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker2:19093
      JMX_PORT: "9998"
#      KAFKA_JMX_OPTS: "-javaagent:/opt/jmx-exporter/jmx_prometheus_javaagent-0.12.0.jar=9081:/opt/jmx-exporter/kafka.yml -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"      
      
  broker3:
    image: confluentinc/cp-kafka:latest
    hostname: broker3
    restart: unless-stopped
    container_name: broker3
    depends_on:
      - zookeeper
      - broker2      
    ports:
      - "19094:19094" 
      - "9082:9082"       
    volumes:
      - ./mount/jmx_exporter:/opt/jmx-exporter/      
    environment:      
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT    
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3    
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:12181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker3:19094
      JMX_PORT: "9997"
#      KAFKA_JMX_OPTS: "-javaagent:/opt/jmx-exporter/jmx_prometheus_javaagent-0.12.0.jar=9082:/opt/jmx-exporter/kafka.yml -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"

  postgres:
    image: postgres:9.6
    hostname: postgresql
    environment:
        - POSTGRES_USER=airflow
        - POSTGRES_PASSWORD=airflow
        - POSTGRES_DB=airflow
    logging:
        options:
            max-size: 10m
            max-file: "3"
    
  webserver:
    image: puckel/docker-airflow:1.10.7
    restart: always
    container_name: webserver
    hostname: webserver    
    depends_on:
        - postgres
    environment:
        - LOAD_EX=n
        - EXECUTOR=Sequential
    logging:
        options:
            max-size: 10m
            max-file: "3"
    volumes:
        - ./dags:/usr/local/airflow/dags
        # - ./plugins:/usr/local/airflow/plugins
    ports:
        - "18080:8080"
    command: webserver
    healthcheck:
        test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
        interval: 30s
        timeout: 30s
        retries: 3
        
  spark-master:
    build:
      context: spark-master/
    container_name: spark-master
    hostname: spark-master
    depends_on:
      - zeppelin   
    ports:
      - "18081:8080"
      - "7077:7077"
      - 14040:4040
      - 33139-33155:33139-33155
      - 45029-45045:45029-45045
    environment:
      - INIT_DAEMON_STEP=setup_spark     
      
  spark-worker-1:
    build:
      context: spark-worker/
    container_name: spark-worker-1
    hostname: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "18082:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"   

  spark-worker-2:
    build:
      context: spark-worker/
    container_name: spark-worker-2
    hostname: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "18083:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"        

  zeppelin:
    container_name: zeppelin
    hostname: zeppelin
    build:
      context: zeppelin/
    restart: unless-stopped
    environment:
      ZEPPELIN_ADDR: "0.0.0.0"
      ZEPPELIN_INTERPRETER_LOCALREPO: /usr/local/local-repo      
      ZEPPELIN_JAVA_OPTS: >-
        -Dspark.driver.memory=1g
        -Dspark.executor.memory=2g
      MASTER: "spark://spark-master:7077"    
    volumes:
      - ./logs:/zeppelin/logs
      - ./notebooks:/zeppelin/notebook
      - ./sample-data:/sample-data:ro
      - ./zeppelin/conf/interpreter.json:/zeppelin/conf/interpreter.json
    ports:
      - 18090:8080
      - 14041:4040      
    labels:
      container_group: "notebook"                 